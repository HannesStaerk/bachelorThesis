\begin{frame}{Gliederung}
	\begin{itemize}
		\item Motivation
		\item Vorwissen
		\item Implementierung, Hardware, Software
		\item Architektur Experimente
		\item Latenter Raum Experimente
		\item Fazit, Wie kann es weiter gehen
	\end{itemize}
\end{frame}

\begin{frame}{Motivation}
	\begin{itemize}
		\item Trial-and-Error Multi-Task Architekturen
		\item Multi-Task Taxonomie
		\item Latente Informationen einzelner Schichten in Single-Task Modellen
		\item Latenten Raum eines Variational Autoencoders verstehen
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=0.6\textwidth]{images/figures/presentation/autoencoder.png}
		\vspace*{15pt}\hbox{\scriptsize Credit:\thinspace{\small\itshape GRID INC}}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=0.7\textwidth]{images/figures/presentation/variational_autoencoder.png}
		\vspace*{15pt}\hbox{\scriptsize Credit:\thinspace{\small\itshape GRID INC}}
	\end{figure}
\end{frame}

\begin{frame}{Implementierung, Hardware, Software}
	\begin{itemize}
		\item Python
		\item Tensorflow
		\item Container der Uni Hannover
		\item Machine-Learning Rechner der UniBw
	\end{itemize}
\end{frame}

\begin{frame}{Architektur Experimente}
	\begin{itemize}
		\item Anzahl von convolutional Schichten
		\item Anzahl von Filtern
		\item Kernel Größe
		\item Max/Average Pooling
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/presentation/bad_reconstructions.jpg}
	\end{figure} 
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/presentation/num_filters_reconstructions.jpg}
	\end{figure} 
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/encoder_neural_network.png}
		\includegraphics[width=\textwidth]{images/figures/decoder_neural_network.png}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/encoder_pooling.png}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=0.8\textwidth]{images/figures/presentation/good_reconstructions.jpg}
	\end{figure}
\end{frame}



\begin{frame}{Latenter Raum Experimente}
	\begin{itemize}
		\item 4000 Bilder $=>$ 4000 Encodings
		\item Dimension reduzieren
		\item Visualisieren
	\end{itemize}
\end{frame}




\begin{frame}{t-Stochastic-Neighbor-Embedding}
	\begin{itemize}
		\item Machine-Learning Verfahren zur Dimensions Reduktion
		\item Besonders gut geeignet für einzelne Visualisierungen
		\item Fokus auf Kontext von Punkten zu ihren Nachbarn
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/presentation/tsne-Classes.jpg}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/presentation/tsne-DSM.jpg}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{images/figures/experiments_latent/convolutional_dim50_images.png}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]
		{images/figures/experiments_latent/convolutional_dim50_images_upwards_observation.png}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]
		{images/figures/experiments_latent/convolutional_dim50_images_sideways_street3.png}
	\end{figure}
\end{frame}

\begin{frame}{Fazit und wie es weiter gehen kann}
	\begin{itemize}
		\item Der VAE lernt nach komplizierten Features zu clustern
		\item Mit t-SNE kann man die Cluster gut visualisieren
		\item Gute Rekonstruktionen vs. Guter Latenter Raum?
		\item Präzisere Methoden um Cluster zu Features zuzuordnen
		\item Als nächstes bei anderen Tasks als bei Autoencodern testen
	\end{itemize}
\end{frame}