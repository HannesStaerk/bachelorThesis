\section{Setup}

\subsection{Data}

The available data are 1024x1024 images of the two United States cities Jacksonville
in Florida and Omaha in Nebraska taken from the US3D Dataset that
was partially published to provide research data for the problem
of 3D reconstruction \parencite{2019-bosch-semantic}.
The images for each recorded area cover one square kilometer and can be divided 
into four categories with the first one being multispectral satellite images with eight channels (MSI). 
From the MSI data three channels were extracted and used as red, green and blue intensities (RGB). 
Thirdly there are digital surface models (DSM) and Lastly semantic labeling with five different categories.
\medskip

The MSI data was collected by the WorldView-3 satellite of Digital Globe from 2014 to 2016.
Thereby the images were taken in different seasons and times of day leading to great differences
in their appearance regarding for instance shadows, reflections, overall brightness or clouds.
This is an advantage for training models that are capable of processing data with similar differences in 
appearance.
In the MSI dataset a single picture consists of eight channels for eight different bands of the spectrum with
a ground sample distance of 1.3 meters. The eight channels of the imagery correspond to the following wavelengths:

\begin{tabular} {c c}
    \parbox{5cm}{
        \begin{itemize}
            \item Coastal: 400 - 450 nm 			
            \item Blue: 450 - 510 nm			
            \item Green: 510 - 580 nm 			
            \item Yellow: 585 - 625 nm
        \end{itemize}
    }
    \parbox{5cm}{
        \begin{enumerate} 			
            \item Red: 630 - 690 nm
            \item Red Edge: 705 - 745 nm
            \item Near-IR1: 770 - 895 nm
            \item Near-IR2: 860 - 1040 nm
        \end{enumerate}
    }
\end{tabular}
\bigskip

Three of those channels were extracted and used as RGB data. 
Each pixel of an image is described by three bytes representing the intensity of either red, green or blue.

The given DSMs were collected using light detection and ranging technology (Lidar). 
They have a single channel that describes the height of each pixel with a greater number 
representing a higher distance to the ground. 

Lastly there are semantic labeled pictures with one channel of a single byte encodes one of five 
different topographic classes. Those classes are vegetation, water, ground, building and clutter. 
The semantic labeling was done automatically from lidar data but manually checked and corrected afterwards.

For all four categories of data the area covered in a single image
is one square kilometer and they contain a lot of oblique view of 
buildings, often with sunshine casting good shadows making the 
data ideal for training models that should detect them.

\subsection{Experiments}

With knowledge about the provided Data we can start thinking about possible experiments to
gain insight into the 