\section{Abstract}


In the area of deep learning, neural networks that solve multiple related tasks in parallel have been
researched and applied as improvements over single task models. Designing such multi task
models often involves a lot of trial and error when determining the right depth for the tasks
to split. Therefore a more systematic taxonomy is desirable to replace this experimentation process.
For constructing this taxonomy it is helpful to have an understanding of the latent information 
learned by specific layers of single task models.

This thesis uses convolutional variational autoencoders to produce latent representations of 
aerial images which are analyzed using techniques that can be used in the context of dissimilar
tasks as well. The method relies on testing whether or not learned clusters can be attributed to
several different high level input features like topographic classes common for the field
of remote sensing. Visualizations are produced which offer insight and an understanding of the
information captured in the latent space of the variational autoencoders.
Moreover, it is observed how different architecture choices affect the reconstructions and the
latent space.
Code and the trained models to reproduce the experiments are publicly available here:
\href{https://github.com/HannesStaerk/bachelorThesis}{https://github.com/HannesStaerk/bachelorThesis}.



