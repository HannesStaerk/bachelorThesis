\section{Architecture}
\subsection{Entropy}

To understand Kullback-Leibler divergence it seems necessary to explain entropy from
the field of information theory. In short, entropy is a measure for the minimum average size an
encoding for a piece of information can possibly have.

To explain that further it is wor