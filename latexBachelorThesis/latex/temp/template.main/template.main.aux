\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Vorwort}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Kurzfassung}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Abstract}{1}{section.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Introduction}{1}{section.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Topic Overview}{1}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Research Questions}{1}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Background}{1}{section.5}\protected@file@percent }
\abx@aux@cite{2005-chrislb-artificial-neuron}
\abx@aux@segm{0}{0}{2005-chrislb-artificial-neuron}
\abx@aux@segm{0}{0}{2005-chrislb-artificial-neuron}
\abx@aux@cite{2017-geron-homl}
\abx@aux@segm{0}{0}{2017-geron-homl}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Remote Sensing}{2}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Artificial Neuron}{2}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An artificial neuron. Image taken from \parencite {2005-chrislb-artificial-neuron}\relax }}{2}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Artificial Neural Network}{2}{subsection.5.3}\protected@file@percent }
\abx@aux@cite{2013-glosser-ann}
\abx@aux@segm{0}{0}{2013-glosser-ann}
\abx@aux@segm{0}{0}{2013-glosser-ann}
\abx@aux@cite{2016-goodfellow-deep}
\abx@aux@segm{0}{0}{2016-goodfellow-deep}
\abx@aux@segm{0}{0}{2017-geron-homl}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An artificial neural network with three fully connected layers. Image taken from \parencite {2013-glosser-ann}\relax }}{3}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure_fully_connected_nn}{{2}{3}{An artificial neural network with three fully connected layers. Image taken from \parencite {2013-glosser-ann}\relax }{figure.caption.3}{}}
\abx@aux@segm{0}{0}{2017-geron-homl}
\abx@aux@segm{0}{0}{2017-geron-homl}
\abx@aux@segm{0}{0}{2016-goodfellow-deep}
\abx@aux@cite{2012-krizhevsky-imagenet}
\abx@aux@segm{0}{0}{2012-krizhevsky-imagenet}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Convolutional Neural Networks}{4}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Pooling}{4}{section*.5}\protected@file@percent }
\abx@aux@cite{2015-Chervinskii-autoencoder}
\abx@aux@segm{0}{0}{2015-Chervinskii-autoencoder}
\abx@aux@segm{0}{0}{2015-Chervinskii-autoencoder}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A convolutional network with 12 filters in the first convolutional layer and 7 filters in the second convolutional layer. Each filters can learn different features and an RGB image is depicted as the input here. Image taken from \parencite {2017-geron-homl}\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{figure_cnn_filter}{{3}{5}{A convolutional network with 12 filters in the first convolutional layer and 7 filters in the second convolutional layer. Each filters can learn different features and an RGB image is depicted as the input here. Image taken from \parencite {2017-geron-homl}\relax }{figure.caption.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Autoencoders}{5}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An undercomplete autoencoder has a latent code $z$ whose dimension is smaller than the dimension of the input $x$. Image taken from \parencite {2015-Chervinskii-autoencoder}\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{figure_undercomplete_ae}{{4}{6}{An undercomplete autoencoder has a latent code $z$ whose dimension is smaller than the dimension of the input $x$. Image taken from \parencite {2015-Chervinskii-autoencoder}\relax }{figure.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Kullback-Leibler Divergence}{6}{subsection.5.6}\protected@file@percent }
\newlabel{KL-Divergence}{{5.6}{6}{Kullback-Leibler Divergence}{subsection.5.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.1}Entropy}{6}{subsubsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.2}Cross Entropy}{7}{subsubsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.3}Kullback-Leibler Divergence}{8}{subsubsection.5.6.3}\protected@file@percent }
\newlabel{eq1}{{3}{8}{Kullback-Leibler Divergence}{equation.5.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Variational Autoencoders}{8}{subsection.5.7}\protected@file@percent }
\newlabel{vae_background}{{5.7}{8}{Variational Autoencoders}{subsection.5.7}{}}
\abx@aux@cite{2016-doersch-tutorial}
\abx@aux@segm{0}{0}{2016-doersch-tutorial}
\abx@aux@cite{2008-vanDerMaaten-visualizing}
\abx@aux@segm{0}{0}{2008-vanDerMaaten-visualizing}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}t-Distributed Stochastic Neighbor Embedding}{9}{subsection.5.8}\protected@file@percent }
\newlabel{t-sne}{{5.8}{9}{t-Distributed Stochastic Neighbor Embedding}{subsection.5.8}{}}
\newlabel{pij}{{4}{9}{t-Distributed Stochastic Neighbor Embedding}{equation.5.4}{}}
\newlabel{qij}{{5}{9}{t-Distributed Stochastic Neighbor Embedding}{equation.5.5}{}}
\abx@aux@cite{2015-springenberg-striving}
\abx@aux@segm{0}{0}{2015-springenberg-striving}
\abx@aux@cite{2016-mishkin-systematic}
\abx@aux@segm{0}{0}{2016-mishkin-systematic}
\abx@aux@cite{2017-klambauer-selu}
\abx@aux@segm{0}{0}{2017-klambauer-selu}
\abx@aux@cite{2018-Pedamonti-comparison}
\abx@aux@segm{0}{0}{2018-Pedamonti-comparison}
\abx@aux@cite{2015-theis-generative}
\abx@aux@segm{0}{0}{2015-theis-generative}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Related Work}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}General and Convolutional Network Architecture}{10}{subsection.6.1}\protected@file@percent }
\newlabel{related_work_general_architecture}{{6.1}{10}{General and Convolutional Network Architecture}{subsection.6.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Variational Autoencoders and Generative Networks}{10}{subsection.6.2}\protected@file@percent }
\abx@aux@cite{1995-rossum-python}
\abx@aux@segm{0}{0}{1995-rossum-python}
\abx@aux@cite{2015-martin-tensorflow}
\abx@aux@segm{0}{0}{2015-martin-tensorflow}
\abx@aux@cite{2011-pedregosa-scikit}
\abx@aux@segm{0}{0}{2011-pedregosa-scikit}
\abx@aux@cite{2019-bosch-semantic}
\abx@aux@segm{0}{0}{2019-bosch-semantic}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Methodology}{11}{section.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Environment}{11}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Hardware}{11}{subsubsection.7.1.1}\protected@file@percent }
\newlabel{hardware}{{7.1.1}{11}{Hardware}{subsubsection.7.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Personal Computer}{11}{section*.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Remote Machine}{11}{section*.8}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Software}{11}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Datasets}{12}{subsection.7.2}\protected@file@percent }
\newlabel{datasets}{{7.2}{12}{Datasets}{subsection.7.2}{}}
\abx@aux@segm{0}{0}{2017-geron-homl}
\abx@aux@segm{0}{0}{2017-klambauer-selu}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Architecture}{13}{subsection.7.3}\protected@file@percent }
\newlabel{architecture}{{7.3}{13}{Architecture}{subsection.7.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Pure Convolutional Architecture}{14}{subsubsection.7.3.1}\protected@file@percent }
\newlabel{section_pure_convolutional_architecture}{{7.3.1}{14}{Pure Convolutional Architecture}{subsubsection.7.3.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Encoder network architecture with an encoding size of 1024. The kernel size is $3\times 3$ in every layer. The reparameterization trick in the last layer refers to the sampling as described in section \ref  {vae_background}. Dimensions are specified as $depth@height\times width$.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{figure_pure_convolutional_encoder}{{5}{14}{Encoder network architecture with an encoding size of 1024. The kernel size is $3\times 3$ in every layer. The reparameterization trick in the last layer refers to the sampling as described in section \ref {vae_background}. Dimensions are specified as $depth@height\times width$.\relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Max Pooling Architecture}{14}{subsubsection.7.3.2}\protected@file@percent }
\abx@aux@segm{0}{0}{2008-vanDerMaaten-visualizing}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Decoder network architecture with an encoding size of 1024. The kernel size is $3\times 3$ in every layer. The last deconvolutional layer has a sigmoid activation function. Dimensions are specified as $depth@height\times width$.\relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{figure_decoder}{{6}{15}{Decoder network architecture with an encoding size of 1024. The kernel size is $3\times 3$ in every layer. The last deconvolutional layer has a sigmoid activation function. Dimensions are specified as $depth@height\times width$.\relax }{figure.caption.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Part of the encoder network architecture with pooling and an encoding size of 1024. The convolutional kernel always has size $3\times 3$. The pooling window always has size $2\times 2$. The rest of the encoder that generates the latent code is the same as in the fully convolutional encoder \ref  {section_pure_convolutional_architecture}. Dimensions are specified as $depth@height\times width$.\relax }}{15}{figure.caption.11}\protected@file@percent }
\newlabel{figure_encoder_pooling}{{7}{15}{Part of the encoder network architecture with pooling and an encoding size of 1024. The convolutional kernel always has size $3\times 3$. The pooling window always has size $2\times 2$. The rest of the encoder that generates the latent code is the same as in the fully convolutional encoder \ref {section_pure_convolutional_architecture}. Dimensions are specified as $depth@height\times width$.\relax }{figure.caption.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Understanding Latent Space}{15}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Experiments}{16}{section.8}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Variational Autoencoder Architecture}{16}{subsection.8.1}\protected@file@percent }
\newlabel{architecture_experiments}{{8.1}{16}{Variational Autoencoder Architecture}{subsection.8.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 1}{17}{section*.12}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The layers of the encoder up to the vector that the two dense layers use to produce the means and standard deviations for the latent code.\relax }}{17}{table.caption.13}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The layers of the decoder.\relax }}{18}{table.caption.14}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The graph depicts the mean of all the mean average errors (MAEs) which were produced in the same epoch for every epoch. \textit  {"MAEs last epoch"} is the mean of the MAEs of the batches in the last epoch, i.e. the last value of the graph. \textit  {"Mean loss last epoch"} is the mean of the losses that the batches in the last epoch produced. Notice that this is not the same as the MAE since loss is the sum of the MAE and the Kullback-Leibler divergence. \textit  {"Total weights"} is the number of weights in the network that are trained.\relax }}{18}{figure.caption.15}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The original images in the top row are taken from a validation set that the VAE has not seen in training. The images in the bottom row are reconstructions of the original produced by the VAE after training.\relax }}{18}{figure.caption.16}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 2}{19}{section*.17}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 3}{19}{section*.22}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 4}{20}{section*.27}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 5}{21}{section*.32}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 6}{22}{section*.37}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 7}{23}{section*.42}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 8}{24}{section*.47}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 9}{25}{section*.52}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 10}{25}{section*.57}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 11}{26}{section*.62}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 12}{27}{section*.67}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 13}{28}{section*.72}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 14}{29}{section*.77}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 15}{30}{section*.82}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 16}{31}{section*.87}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 17}{32}{section*.92}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Architecture 18}{33}{section*.97}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Latent Space}{34}{subsection.8.2}\protected@file@percent }
\newlabel{latent_space_experiments}{{8.2}{34}{Latent Space}{subsection.8.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {9}Conclusion and Future Work}{34}{section.9}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Conclusion}{34}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Future Work}{34}{subsection.9.2}\protected@file@percent }
